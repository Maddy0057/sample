# ChatGPT Clone - Mobile

A mobile-first ChatGPT clone built with modern web technologies, designed exclusively for mobile viewports with a maximum width of 480px.

## Project Live Demo Link üöÄ
https://sample-swart-ten.vercel.app/
AND VIDEO LINK
https://www.youtube.com/watch?v=SAyKeJPQJ34

## üöÄ Project Overview

This application is a proof-of-concept mobile ChatGPT clone that demonstrates the integration of:

- **Next.js 14** with App Router for the frontend framework
- **tRPC** for type-safe client-server communication
- **Supabase** for user chat history persistence
- **Auth0** for secure user authentication
- **Google Gemini AI** for text generation
- **Hugging Face Inference API** for image generation
- **Bootstrap** for mobile-first UI components

The application features a single-page chat interface optimized for mobile devices, with support for both text conversations and image generation using the `/imagine` command.

## üõ†Ô∏è Tech Stack

- **Frontend Framework**: Next.js 14 (App Router)
- **Language**: TypeScript
- **UI Library**: Bootstrap 5.3.2 + React Bootstrap
- **API Layer**: tRPC (type-safe RPC)
- **Database**: Supabase (PostgreSQL)
- **Authentication**: Auth0
- **AI Provider (Text)**: Google AI Studio (Gemini APIs)
- **AI Provider (Images)**: Hugging Face Inference API (Stable Diffusion 2.1)
- **State Management**: TanStack React Query
- **Styling**: Custom CSS with mobile-first design

## üîß Environment Variable Setup

Create a `.env.local` file in your project root with the following variables:

### Supabase Configuration
```env
NEXT_PUBLIC_SUPABASE_URL=your_supabase_project_url
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_supabase_anon_key
SUPABASE_SERVICE_ROLE_KEY=your_supabase_service_role_key
```

### Auth0 Configuration
```env
AUTH0_SECRET=your_auth0_secret
AUTH0_BASE_URL=http://localhost:3000
AUTH0_ISSUER_BASE_URL=https://your-domain.auth0.com
AUTH0_CLIENT_ID=your_auth0_client_id
AUTH0_CLIENT_SECRET=your_auth0_client_secret
```

### Google AI Studio (Gemini) Configuration
```env
GOOGLE_AI_API_KEY=your_google_ai_api_key
```

### Hugging Face Inference API (Images)
```env
HUGGINGFACE_API_KEY=your_huggingface_api_key
```

## üóÑÔ∏è Database Setup

Run the SQL from `supabase-schema.sql` in your Supabase SQL editor.

## üîê Auth0 Setup

Configure callback/logout/origin URLs as documented earlier.

## ü§ñ Image Generation (Hugging Face)

We use the free Hugging Face Inference API with Stable Diffusion 2.1.

### 1) Get a Token
- Create an account on `https://huggingface.co`
- Go to Settings ‚Üí Access Tokens ‚Üí New token (Type: Read)
- Copy the token and set `HUGGINGFACE_API_KEY` in `.env.local`

### 2) Use the Feature
- In chat, type: `/imagine a cat wearing sunglasses, photorealistic`
- The server will call Hugging Face and return a base64 image, which is persisted and shown inline.

### Notes
- Free tier may queue or return 503 while the model warms up; the app shows a friendly fallback and keeps your message.
- For production, consider using a dedicated inference endpoint or hosting your own model for better latency.

## üöÄ Local Development

```bash
npm install
cp env.example .env.local
npm run dev
```

## Deployment to Vercel

Add all env vars (including `HUGGINGFACE_API_KEY`) in the Vercel dashboard before deploying.
